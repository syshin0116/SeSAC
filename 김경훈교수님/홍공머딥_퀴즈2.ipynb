{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299f5651-95ec-4a06-8fe3-3ad4723a14fd",
   "metadata": {},
   "source": [
    "y = 0.55x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "097d9ac2-a9e0-4011-832a-c80373186ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060b439-bf33-4fd4-aa04-30a2f166baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x):\n",
    "    return 0.55*x + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1d8c28-2b46-4668-bd00-48b952d9a96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>55.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>56.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>56.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>57.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>58.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x      y\n",
       "0     1   3.55\n",
       "1     2   4.10\n",
       "2     3   4.65\n",
       "3     4   5.20\n",
       "4     5   5.75\n",
       "..  ...    ...\n",
       "95   96  55.80\n",
       "96   97  56.35\n",
       "97   98  56.90\n",
       "98   99  57.45\n",
       "99  100  58.00\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'x': [x for x in range(1, 101)],\n",
    "        'y': [func1(x) for x in range(1, 101)]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e83b4c-ce26-43cf-87df-e1a558760468",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df['x']).reshape(-1, 1)\n",
    "target = np.array(df['y']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2e281f-8078-4b8a-98a4-27eb4ced0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b4e4e6-8933-40fc-ad20-9ec314ebb5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                100       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,650\n",
      "Trainable params: 2,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 11:18:52.239444: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-07 11:18:52.239579: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='linear', input_dim=1))\n",
    "model.add(keras.layers.Dense(50, activation='linear', input_dim=1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790ebd0d-ea2b-48e3-8d69-cfcf90fcd5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 11:18:52.361057: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-09-07 11:18:52.474519: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 1673.4362 - mae: 34.9022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 11:18:52.634655: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 118ms/step - loss: 1443.7065 - mae: 32.2751 - val_loss: 808.6352 - val_mae: 22.6281\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 732.2084 - mae: 22.2130 - val_loss: 350.8645 - val_mae: 14.1467\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 287.8254 - mae: 12.9379 - val_loss: 116.0898 - val_mae: 7.6308\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 101.4413 - mae: 7.3517 - val_loss: 64.6974 - val_mae: 6.1510\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 78.3442 - mae: 6.7860 - val_loss: 93.6371 - val_mae: 7.1275\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 106.6107 - mae: 8.0181 - val_loss: 99.3280 - val_mae: 7.7102\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 99.2716 - mae: 8.0232 - val_loss: 70.3396 - val_mae: 6.4819\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 65.6492 - mae: 6.2799 - val_loss: 44.1237 - val_mae: 4.9701\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 42.5189 - mae: 4.9722 - val_loss: 35.0107 - val_mae: 4.6556\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 37.5943 - mae: 4.9209 - val_loss: 38.2547 - val_mae: 5.1262\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 42.0016 - mae: 5.4396 - val_loss: 40.4006 - val_mae: 5.3717\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 42.0907 - mae: 5.5340 - val_loss: 33.5665 - val_mae: 4.9513\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 32.6895 - mae: 4.9228 - val_loss: 22.1985 - val_mae: 4.1307\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 20.2356 - mae: 3.9437 - val_loss: 12.8457 - val_mae: 3.1424\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 11.7003 - mae: 2.8888 - val_loss: 9.7378 - val_mae: 2.4618\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.7492 - mae: 2.3062 - val_loss: 11.3110 - val_mae: 2.4817\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 11.8220 - mae: 2.4544 - val_loss: 12.3826 - val_mae: 2.6830\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 11.7678 - mae: 2.5470 - val_loss: 9.8889 - val_mae: 2.4948\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 8.8560 - mae: 2.3070 - val_loss: 6.6848 - val_mae: 2.1904\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 5.7447 - mae: 1.9874 - val_loss: 5.5117 - val_mae: 2.0728\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.0601 - mae: 1.9131 - val_loss: 5.9876 - val_mae: 2.1175\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.7761 - mae: 2.0095 - val_loss: 6.3098 - val_mae: 2.1636\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.8465 - mae: 2.0480 - val_loss: 5.4734 - val_mae: 2.0639\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 4.6785 - mae: 1.8844 - val_loss: 4.0789 - val_mae: 1.8016\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.2305 - mae: 1.5715 - val_loss: 3.2317 - val_mae: 1.5714\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4802 - mae: 1.3396 - val_loss: 3.3019 - val_mae: 1.5664\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.7283 - mae: 1.3647 - val_loss: 3.6833 - val_mae: 1.6405\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.0247 - mae: 1.4166 - val_loss: 3.5948 - val_mae: 1.6163\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.8386 - mae: 1.3784 - val_loss: 3.1044 - val_mae: 1.5026\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 2.3050 - mae: 1.2609 - val_loss: 2.7314 - val_mae: 1.4090\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 2.0113 - mae: 1.1936 - val_loss: 2.6511 - val_mae: 1.3812\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0511 - mae: 1.2196 - val_loss: 2.7064 - val_mae: 1.4035\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1089 - mae: 1.2425 - val_loss: 2.6534 - val_mae: 1.3787\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.0197 - mae: 1.2034 - val_loss: 2.4886 - val_mae: 1.3229\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.8303 - mae: 1.1333 - val_loss: 2.3667 - val_mae: 1.2927\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.7144 - mae: 1.0975 - val_loss: 2.3437 - val_mae: 1.3007\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6957 - mae: 1.0941 - val_loss: 2.3359 - val_mae: 1.3085\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6931 - mae: 1.0957 - val_loss: 2.2725 - val_mae: 1.2822\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.6351 - mae: 1.0738 - val_loss: 2.1938 - val_mae: 1.2421\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.5919 - mae: 1.0569 - val_loss: 2.1431 - val_mae: 1.2109\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.5420 - mae: 1.0324 - val_loss: 2.1183 - val_mae: 1.1993\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.5333 - mae: 1.0287 - val_loss: 2.0841 - val_mae: 1.1861\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.5011 - mae: 1.0168 - val_loss: 2.0343 - val_mae: 1.1712\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4526 - mae: 1.0030 - val_loss: 1.9917 - val_mae: 1.1631\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4179 - mae: 0.9935 - val_loss: 1.9683 - val_mae: 1.1642\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4049 - mae: 0.9898 - val_loss: 1.9502 - val_mae: 1.1666\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3927 - mae: 0.9885 - val_loss: 1.9210 - val_mae: 1.1585\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3621 - mae: 0.9763 - val_loss: 1.8798 - val_mae: 1.1378\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3329 - mae: 0.9634 - val_loss: 1.8433 - val_mae: 1.1179\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3200 - mae: 0.9594 - val_loss: 1.8161 - val_mae: 1.1034\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.3007 - mae: 0.9476 - val_loss: 1.7874 - val_mae: 1.0934\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.2766 - mae: 0.9411 - val_loss: 1.7556 - val_mae: 1.0876\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.2460 - mae: 0.9306 - val_loss: 1.7293 - val_mae: 1.0845\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.2260 - mae: 0.9236 - val_loss: 1.7052 - val_mae: 1.0819\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.2093 - mae: 0.9184 - val_loss: 1.6776 - val_mae: 1.0731\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1886 - mae: 0.9105 - val_loss: 1.6486 - val_mae: 1.0620\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.1694 - mae: 0.9027 - val_loss: 1.6201 - val_mae: 1.0511\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1478 - mae: 0.8936 - val_loss: 1.5911 - val_mae: 1.0371\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1309 - mae: 0.8863 - val_loss: 1.5637 - val_mae: 1.0236\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1117 - mae: 0.8780 - val_loss: 1.5370 - val_mae: 1.0141\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0933 - mae: 0.8708 - val_loss: 1.5109 - val_mae: 1.0092\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0827 - mae: 0.8698 - val_loss: 1.4886 - val_mae: 1.0098\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0541 - mae: 0.8570 - val_loss: 1.4624 - val_mae: 0.9995\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0365 - mae: 0.8492 - val_loss: 1.4351 - val_mae: 0.9866\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0162 - mae: 0.8402 - val_loss: 1.4087 - val_mae: 0.9729\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0109 - mae: 0.8392 - val_loss: 1.3844 - val_mae: 0.9598\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9855 - mae: 0.8277 - val_loss: 1.3593 - val_mae: 0.9548\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9673 - mae: 0.8197 - val_loss: 1.3368 - val_mae: 0.9538\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9469 - mae: 0.8115 - val_loss: 1.3133 - val_mae: 0.9468\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9313 - mae: 0.8054 - val_loss: 1.2900 - val_mae: 0.9391\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9138 - mae: 0.7971 - val_loss: 1.2647 - val_mae: 0.9265\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8978 - mae: 0.7904 - val_loss: 1.2398 - val_mae: 0.9107\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8799 - mae: 0.7809 - val_loss: 1.2166 - val_mae: 0.9020\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8644 - mae: 0.7739 - val_loss: 1.1940 - val_mae: 0.8934\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8493 - mae: 0.7684 - val_loss: 1.1729 - val_mae: 0.8915\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8318 - mae: 0.7607 - val_loss: 1.1516 - val_mae: 0.8863\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8153 - mae: 0.7523 - val_loss: 1.1285 - val_mae: 0.8749\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8017 - mae: 0.7463 - val_loss: 1.1070 - val_mae: 0.8670\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7919 - mae: 0.7418 - val_loss: 1.0840 - val_mae: 0.8500\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7695 - mae: 0.7294 - val_loss: 1.0627 - val_mae: 0.8423\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7550 - mae: 0.7238 - val_loss: 1.0427 - val_mae: 0.8391\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7390 - mae: 0.7158 - val_loss: 1.0230 - val_mae: 0.8336\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7240 - mae: 0.7083 - val_loss: 1.0020 - val_mae: 0.8236\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7108 - mae: 0.7015 - val_loss: 0.9810 - val_mae: 0.8115\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6956 - mae: 0.6939 - val_loss: 0.9617 - val_mae: 0.8050\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6813 - mae: 0.6869 - val_loss: 0.9417 - val_mae: 0.7947\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6690 - mae: 0.6801 - val_loss: 0.9223 - val_mae: 0.7843\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6550 - mae: 0.6740 - val_loss: 0.9045 - val_mae: 0.7819\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6417 - mae: 0.6664 - val_loss: 0.8851 - val_mae: 0.7716\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6283 - mae: 0.6593 - val_loss: 0.8673 - val_mae: 0.7665\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6138 - mae: 0.6515 - val_loss: 0.8490 - val_mae: 0.7575\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6022 - mae: 0.6444 - val_loss: 0.8301 - val_mae: 0.7441\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5893 - mae: 0.6373 - val_loss: 0.8123 - val_mae: 0.7347\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5763 - mae: 0.6300 - val_loss: 0.7951 - val_mae: 0.7293\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5629 - mae: 0.6232 - val_loss: 0.7787 - val_mae: 0.7245\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5514 - mae: 0.6166 - val_loss: 0.7624 - val_mae: 0.7182\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5398 - mae: 0.6101 - val_loss: 0.7457 - val_mae: 0.7100\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5283 - mae: 0.6037 - val_loss: 0.7284 - val_mae: 0.6968\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5170 - mae: 0.5957 - val_loss: 0.7122 - val_mae: 0.6869\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5060 - mae: 0.5892 - val_loss: 0.6968 - val_mae: 0.6827\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4933 - mae: 0.5823 - val_loss: 0.6816 - val_mae: 0.6761\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4830 - mae: 0.5762 - val_loss: 0.6660 - val_mae: 0.6664\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4722 - mae: 0.5693 - val_loss: 0.6515 - val_mae: 0.6612\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4610 - mae: 0.5623 - val_loss: 0.6365 - val_mae: 0.6519\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4507 - mae: 0.5555 - val_loss: 0.6219 - val_mae: 0.6431\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4408 - mae: 0.5492 - val_loss: 0.6076 - val_mae: 0.6355\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4298 - mae: 0.5424 - val_loss: 0.5941 - val_mae: 0.6297\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4211 - mae: 0.5364 - val_loss: 0.5801 - val_mae: 0.6202\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4103 - mae: 0.5294 - val_loss: 0.5670 - val_mae: 0.6147\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4016 - mae: 0.5236 - val_loss: 0.5537 - val_mae: 0.6067\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3919 - mae: 0.5168 - val_loss: 0.5407 - val_mae: 0.5992\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3834 - mae: 0.5112 - val_loss: 0.5284 - val_mae: 0.5942\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3745 - mae: 0.5059 - val_loss: 0.5159 - val_mae: 0.5870\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3658 - mae: 0.4980 - val_loss: 0.5030 - val_mae: 0.5739\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3574 - mae: 0.4925 - val_loss: 0.4911 - val_mae: 0.5660\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3501 - mae: 0.4888 - val_loss: 0.4799 - val_mae: 0.5646\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3413 - mae: 0.4823 - val_loss: 0.4692 - val_mae: 0.5609\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3315 - mae: 0.4743 - val_loss: 0.4568 - val_mae: 0.5495\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3235 - mae: 0.4675 - val_loss: 0.4452 - val_mae: 0.5392\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3150 - mae: 0.4610 - val_loss: 0.4344 - val_mae: 0.5308\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3083 - mae: 0.4558 - val_loss: 0.4238 - val_mae: 0.5242\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3005 - mae: 0.4493 - val_loss: 0.4135 - val_mae: 0.5211\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2958 - mae: 0.4469 - val_loss: 0.4051 - val_mae: 0.5209\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2865 - mae: 0.4396 - val_loss: 0.3939 - val_mae: 0.5109\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2788 - mae: 0.4336 - val_loss: 0.3832 - val_mae: 0.4977\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2716 - mae: 0.4261 - val_loss: 0.3736 - val_mae: 0.4902\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2650 - mae: 0.4207 - val_loss: 0.3642 - val_mae: 0.4847\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2585 - mae: 0.4156 - val_loss: 0.3554 - val_mae: 0.4816\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2515 - mae: 0.4094 - val_loss: 0.3463 - val_mae: 0.4748\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2460 - mae: 0.4051 - val_loss: 0.3377 - val_mae: 0.4697\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2386 - mae: 0.3983 - val_loss: 0.3288 - val_mae: 0.4610\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2332 - mae: 0.3934 - val_loss: 0.3201 - val_mae: 0.4519\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2271 - mae: 0.3874 - val_loss: 0.3121 - val_mae: 0.4473\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2205 - mae: 0.3817 - val_loss: 0.3042 - val_mae: 0.4412\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2155 - mae: 0.3769 - val_loss: 0.2966 - val_mae: 0.4371\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2116 - mae: 0.3735 - val_loss: 0.2892 - val_mae: 0.4326\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2043 - mae: 0.3665 - val_loss: 0.2812 - val_mae: 0.4230\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2010 - mae: 0.3634 - val_loss: 0.2741 - val_mae: 0.4143\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1946 - mae: 0.3559 - val_loss: 0.2667 - val_mae: 0.4096\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1887 - mae: 0.3504 - val_loss: 0.2600 - val_mae: 0.4060\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1840 - mae: 0.3465 - val_loss: 0.2541 - val_mae: 0.4048\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1800 - mae: 0.3423 - val_loss: 0.2474 - val_mae: 0.3987\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1747 - mae: 0.3364 - val_loss: 0.2401 - val_mae: 0.3889\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1695 - mae: 0.3301 - val_loss: 0.2337 - val_mae: 0.3806\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1658 - mae: 0.3260 - val_loss: 0.2275 - val_mae: 0.3744\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1612 - mae: 0.3210 - val_loss: 0.2214 - val_mae: 0.3697\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1565 - mae: 0.3164 - val_loss: 0.2160 - val_mae: 0.3683\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1527 - mae: 0.3120 - val_loss: 0.2104 - val_mae: 0.3632\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1491 - mae: 0.3081 - val_loss: 0.2049 - val_mae: 0.3584\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1449 - mae: 0.3033 - val_loss: 0.1991 - val_mae: 0.3508\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1407 - mae: 0.2985 - val_loss: 0.1936 - val_mae: 0.3423\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1371 - mae: 0.2930 - val_loss: 0.1886 - val_mae: 0.3371\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1336 - mae: 0.2887 - val_loss: 0.1834 - val_mae: 0.3326\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1300 - mae: 0.2848 - val_loss: 0.1788 - val_mae: 0.3308\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1264 - mae: 0.2806 - val_loss: 0.1743 - val_mae: 0.3270\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1235 - mae: 0.2766 - val_loss: 0.1692 - val_mae: 0.3199\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1204 - mae: 0.2729 - val_loss: 0.1645 - val_mae: 0.3113\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1167 - mae: 0.2668 - val_loss: 0.1601 - val_mae: 0.3071\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1133 - mae: 0.2627 - val_loss: 0.1559 - val_mae: 0.3037\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1103 - mae: 0.2589 - val_loss: 0.1518 - val_mae: 0.2994\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1073 - mae: 0.2548 - val_loss: 0.1478 - val_mae: 0.2955\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1046 - mae: 0.2508 - val_loss: 0.1440 - val_mae: 0.2915\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1016 - mae: 0.2466 - val_loss: 0.1400 - val_mae: 0.2858\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0990 - mae: 0.2426 - val_loss: 0.1363 - val_mae: 0.2807\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0963 - mae: 0.2386 - val_loss: 0.1326 - val_mae: 0.2753\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0940 - mae: 0.2350 - val_loss: 0.1290 - val_mae: 0.2701\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0913 - mae: 0.2309 - val_loss: 0.1257 - val_mae: 0.2672\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0891 - mae: 0.2279 - val_loss: 0.1225 - val_mae: 0.2649\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0865 - mae: 0.2239 - val_loss: 0.1191 - val_mae: 0.2592\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0844 - mae: 0.2198 - val_loss: 0.1159 - val_mae: 0.2525\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0822 - mae: 0.2163 - val_loss: 0.1128 - val_mae: 0.2484\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0798 - mae: 0.2124 - val_loss: 0.1099 - val_mae: 0.2458\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0777 - mae: 0.2091 - val_loss: 0.1072 - val_mae: 0.2430\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0758 - mae: 0.2060 - val_loss: 0.1045 - val_mae: 0.2399\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0737 - mae: 0.2025 - val_loss: 0.1016 - val_mae: 0.2346\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0719 - mae: 0.1990 - val_loss: 0.0989 - val_mae: 0.2290\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0699 - mae: 0.1955 - val_loss: 0.0963 - val_mae: 0.2254\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0682 - mae: 0.1922 - val_loss: 0.0938 - val_mae: 0.2216\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0666 - mae: 0.1892 - val_loss: 0.0914 - val_mae: 0.2177\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0649 - mae: 0.1864 - val_loss: 0.0892 - val_mae: 0.2162\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0631 - mae: 0.1832 - val_loss: 0.0869 - val_mae: 0.2122\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0614 - mae: 0.1798 - val_loss: 0.0845 - val_mae: 0.2066\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0600 - mae: 0.1767 - val_loss: 0.0825 - val_mae: 0.2028\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0585 - mae: 0.1741 - val_loss: 0.0804 - val_mae: 0.2001\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0569 - mae: 0.1702 - val_loss: 0.0784 - val_mae: 0.1977\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0555 - mae: 0.1677 - val_loss: 0.0765 - val_mae: 0.1949\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0541 - mae: 0.1651 - val_loss: 0.0745 - val_mae: 0.1909\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0527 - mae: 0.1622 - val_loss: 0.0726 - val_mae: 0.1874\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0514 - mae: 0.1595 - val_loss: 0.0709 - val_mae: 0.1845\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0503 - mae: 0.1577 - val_loss: 0.0692 - val_mae: 0.1820\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0492 - mae: 0.1554 - val_loss: 0.0675 - val_mae: 0.1793\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0477 - mae: 0.1520 - val_loss: 0.0658 - val_mae: 0.1756\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0468 - mae: 0.1512 - val_loss: 0.0643 - val_mae: 0.1724\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0457 - mae: 0.1480 - val_loss: 0.0627 - val_mae: 0.1701\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0445 - mae: 0.1458 - val_loss: 0.0614 - val_mae: 0.1711\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0435 - mae: 0.1447 - val_loss: 0.0599 - val_mae: 0.1674\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0424 - mae: 0.1420 - val_loss: 0.0584 - val_mae: 0.1642\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0415 - mae: 0.1404 - val_loss: 0.0571 - val_mae: 0.1619\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0404 - mae: 0.1380 - val_loss: 0.0558 - val_mae: 0.1600\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0396 - mae: 0.1365 - val_loss: 0.0547 - val_mae: 0.1590\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0387 - mae: 0.1343 - val_loss: 0.0533 - val_mae: 0.1555\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0378 - mae: 0.1324 - val_loss: 0.0521 - val_mae: 0.1534\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0369 - mae: 0.1308 - val_loss: 0.0509 - val_mae: 0.1506\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0361 - mae: 0.1288 - val_loss: 0.0498 - val_mae: 0.1488\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0353 - mae: 0.1272 - val_loss: 0.0488 - val_mae: 0.1478\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0346 - mae: 0.1261 - val_loss: 0.0478 - val_mae: 0.1466\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0338 - mae: 0.1243 - val_loss: 0.0467 - val_mae: 0.1445\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0331 - mae: 0.1231 - val_loss: 0.0457 - val_mae: 0.1427\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0325 - mae: 0.1219 - val_loss: 0.0448 - val_mae: 0.1416\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0318 - mae: 0.1206 - val_loss: 0.0439 - val_mae: 0.1402\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0310 - mae: 0.1188 - val_loss: 0.0429 - val_mae: 0.1377\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0304 - mae: 0.1175 - val_loss: 0.0420 - val_mae: 0.1358\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0298 - mae: 0.1162 - val_loss: 0.0412 - val_mae: 0.1345\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0292 - mae: 0.1149 - val_loss: 0.0403 - val_mae: 0.1335\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0287 - mae: 0.1139 - val_loss: 0.0395 - val_mae: 0.1314\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0280 - mae: 0.1124 - val_loss: 0.0388 - val_mae: 0.1304\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0274 - mae: 0.1112 - val_loss: 0.0380 - val_mae: 0.1294\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0271 - mae: 0.1106 - val_loss: 0.0374 - val_mae: 0.1292\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0265 - mae: 0.1093 - val_loss: 0.0367 - val_mae: 0.1276\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0260 - mae: 0.1083 - val_loss: 0.0359 - val_mae: 0.1262\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0255 - mae: 0.1073 - val_loss: 0.0353 - val_mae: 0.1243\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0252 - mae: 0.1069 - val_loss: 0.0346 - val_mae: 0.1221\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0246 - mae: 0.1047 - val_loss: 0.0340 - val_mae: 0.1222\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0241 - mae: 0.1045 - val_loss: 0.0335 - val_mae: 0.1223\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0237 - mae: 0.1036 - val_loss: 0.0328 - val_mae: 0.1197\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0234 - mae: 0.1026 - val_loss: 0.0322 - val_mae: 0.1190\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0229 - mae: 0.1018 - val_loss: 0.0317 - val_mae: 0.1181\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0225 - mae: 0.1004 - val_loss: 0.0312 - val_mae: 0.1175\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0222 - mae: 0.1000 - val_loss: 0.0307 - val_mae: 0.1169\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0217 - mae: 0.0986 - val_loss: 0.0301 - val_mae: 0.1149\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0213 - mae: 0.0978 - val_loss: 0.0296 - val_mae: 0.1136\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0212 - mae: 0.0978 - val_loss: 0.0291 - val_mae: 0.1121\n",
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0207 - mae: 0.0961 - val_loss: 0.0286 - val_mae: 0.1122\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0206 - mae: 0.0971 - val_loss: 0.0283 - val_mae: 0.1128\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0201 - mae: 0.0956 - val_loss: 0.0277 - val_mae: 0.1110\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0197 - mae: 0.0943 - val_loss: 0.0273 - val_mae: 0.1107\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0194 - mae: 0.0947 - val_loss: 0.0269 - val_mae: 0.1090\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0191 - mae: 0.0931 - val_loss: 0.0265 - val_mae: 0.1081\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0188 - mae: 0.0921 - val_loss: 0.0261 - val_mae: 0.1073\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0187 - mae: 0.0923 - val_loss: 0.0257 - val_mae: 0.1068\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0182 - mae: 0.0906 - val_loss: 0.0253 - val_mae: 0.1057\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0179 - mae: 0.0904 - val_loss: 0.0249 - val_mae: 0.1053\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0177 - mae: 0.0899 - val_loss: 0.0245 - val_mae: 0.1039\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0174 - mae: 0.0885 - val_loss: 0.0242 - val_mae: 0.1036\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0172 - mae: 0.0883 - val_loss: 0.0238 - val_mae: 0.1031\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0169 - mae: 0.0876 - val_loss: 0.0235 - val_mae: 0.1017\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0167 - mae: 0.0869 - val_loss: 0.0231 - val_mae: 0.1013\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0166 - mae: 0.0868 - val_loss: 0.0228 - val_mae: 0.1010\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0162 - mae: 0.0857 - val_loss: 0.0225 - val_mae: 0.1003\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0160 - mae: 0.0851 - val_loss: 0.0222 - val_mae: 0.0994\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0157 - mae: 0.0847 - val_loss: 0.0219 - val_mae: 0.0986\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0155 - mae: 0.0842 - val_loss: 0.0216 - val_mae: 0.0980\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0154 - mae: 0.0840 - val_loss: 0.0213 - val_mae: 0.0980\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0151 - mae: 0.0833 - val_loss: 0.0210 - val_mae: 0.0973\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0149 - mae: 0.0830 - val_loss: 0.0208 - val_mae: 0.0967\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0147 - mae: 0.0826 - val_loss: 0.0205 - val_mae: 0.0961\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0146 - mae: 0.0821 - val_loss: 0.0202 - val_mae: 0.0961\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0144 - mae: 0.0817 - val_loss: 0.0200 - val_mae: 0.0956\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0142 - mae: 0.0814 - val_loss: 0.0197 - val_mae: 0.0952\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0140 - mae: 0.0811 - val_loss: 0.0195 - val_mae: 0.0947\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0139 - mae: 0.0810 - val_loss: 0.0193 - val_mae: 0.0946\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0137 - mae: 0.0804 - val_loss: 0.0190 - val_mae: 0.0941\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0135 - mae: 0.0798 - val_loss: 0.0188 - val_mae: 0.0933\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0133 - mae: 0.0795 - val_loss: 0.0185 - val_mae: 0.0926\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0132 - mae: 0.0793 - val_loss: 0.0183 - val_mae: 0.0917\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0130 - mae: 0.0788 - val_loss: 0.0181 - val_mae: 0.0919\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0128 - mae: 0.0784 - val_loss: 0.0179 - val_mae: 0.0915\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0127 - mae: 0.0780 - val_loss: 0.0177 - val_mae: 0.0913\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0126 - mae: 0.0778 - val_loss: 0.0175 - val_mae: 0.0913\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0124 - mae: 0.0774 - val_loss: 0.0173 - val_mae: 0.0909\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0123 - mae: 0.0770 - val_loss: 0.0171 - val_mae: 0.0903\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0122 - mae: 0.0768 - val_loss: 0.0169 - val_mae: 0.0892\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0120 - mae: 0.0762 - val_loss: 0.0167 - val_mae: 0.0886\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0118 - mae: 0.0759 - val_loss: 0.0165 - val_mae: 0.0884\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0117 - mae: 0.0756 - val_loss: 0.0163 - val_mae: 0.0883\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0116 - mae: 0.0751 - val_loss: 0.0161 - val_mae: 0.0879\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0114 - mae: 0.0749 - val_loss: 0.0159 - val_mae: 0.0875\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0113 - mae: 0.0745 - val_loss: 0.0157 - val_mae: 0.0870\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0112 - mae: 0.0743 - val_loss: 0.0156 - val_mae: 0.0869\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0110 - mae: 0.0739 - val_loss: 0.0154 - val_mae: 0.0865\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0109 - mae: 0.0735 - val_loss: 0.0152 - val_mae: 0.0860\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0108 - mae: 0.0732 - val_loss: 0.0150 - val_mae: 0.0852\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0107 - mae: 0.0728 - val_loss: 0.0149 - val_mae: 0.0846\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0106 - mae: 0.0725 - val_loss: 0.0147 - val_mae: 0.0843\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0105 - mae: 0.0722 - val_loss: 0.0146 - val_mae: 0.0844\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0103 - mae: 0.0720 - val_loss: 0.0144 - val_mae: 0.0843\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0102 - mae: 0.0716 - val_loss: 0.0142 - val_mae: 0.0838\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0101 - mae: 0.0712 - val_loss: 0.0141 - val_mae: 0.0831\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0100 - mae: 0.0708 - val_loss: 0.0139 - val_mae: 0.0827\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0099 - mae: 0.0705 - val_loss: 0.0138 - val_mae: 0.0822\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0098 - mae: 0.0701 - val_loss: 0.0136 - val_mae: 0.0818\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0097 - mae: 0.0700 - val_loss: 0.0135 - val_mae: 0.0818\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0096 - mae: 0.0696 - val_loss: 0.0133 - val_mae: 0.0815\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0095 - mae: 0.0692 - val_loss: 0.0132 - val_mae: 0.0809\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0094 - mae: 0.0688 - val_loss: 0.0130 - val_mae: 0.0801\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0093 - mae: 0.0684 - val_loss: 0.0129 - val_mae: 0.0796\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0092 - mae: 0.0682 - val_loss: 0.0128 - val_mae: 0.0795\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0091 - mae: 0.0678 - val_loss: 0.0126 - val_mae: 0.0792\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0090 - mae: 0.0675 - val_loss: 0.0125 - val_mae: 0.0791\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.0089 - mae: 0.0673 - val_loss: 0.0124 - val_mae: 0.0788\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('quiz_best_model.h5', save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history= model.fit(train_input, train_target, epochs=300, validation_data=(val_input, val_target), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6863047d-e1ee-484d-901a-d3e301716fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a0dc7c-2977-435b-a7bc-c03aa0fee554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0124 - mae: 0.0788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.012367729097604752, 0.07881699502468109]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_input, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "840bd60f-70c2-4e54-b318-5f0f5f7d0c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0112 - mae: 0.0774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.011211537756025791, 0.07742522656917572]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5380a75d-bfa2-4935-834f-8af65c25aeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.11559334, -0.00876668, -0.18168966, -0.03698098,  0.17869513,\n",
       "         -0.08885773,  0.00546062,  0.08479103, -0.01473973,  0.186826  ,\n",
       "          0.18927518, -0.08589906, -0.12083373, -0.07106612,  0.04435939,\n",
       "          0.06796143,  0.06048255, -0.15584485, -0.02664892, -0.10734937,\n",
       "         -0.02673807,  0.02909631, -0.04931472, -0.18823135,  0.15417525,\n",
       "          0.1622377 , -0.13105294, -0.12967597, -0.1298759 ,  0.07573295,\n",
       "         -0.04843432, -0.06740732,  0.00775599,  0.29029453,  0.06969505,\n",
       "         -0.15055582, -0.06044776,  0.26532975,  0.00576312,  0.2581944 ,\n",
       "         -0.3254689 ,  0.02584914, -0.16120315, -0.305972  ,  0.13485464,\n",
       "          0.08537389, -0.13870789, -0.2608599 ,  0.05351935,  0.3296551 ]],\n",
       "       dtype=float32),\n",
       " array([-0.5863636 , -0.5129806 , -0.07125358, -0.7878708 ,  0.6915263 ,\n",
       "        -0.46097758,  0.5185125 ,  0.49822912, -0.43983936,  0.7786785 ,\n",
       "         0.7385697 , -0.57865286, -0.08443517, -0.6293876 ,  0.60834664,\n",
       "         0.55567175,  0.43167707, -0.8097966 , -0.6499362 , -0.52514267,\n",
       "         0.52940077, -0.18977425, -0.6516397 , -0.70686364,  0.62961376,\n",
       "         0.61687934, -0.6164776 , -0.6252691 , -0.4555232 ,  0.44622657,\n",
       "        -0.5012815 , -0.49372745, -0.25863966,  0.6630171 ,  0.6323949 ,\n",
       "        -0.68276995, -0.34250614,  0.77367413, -0.3414056 ,  0.70248246,\n",
       "        -0.76450914,  0.4025662 , -0.3377938 , -0.751538  ,  0.6151161 ,\n",
       "         0.57109326, -0.7566035 , -0.7713759 ,  0.52381796,  0.66001356],\n",
       "       dtype=float32),\n",
       " array([[ 0.13096783, -0.132141  , -0.356291  , ..., -0.1400099 ,\n",
       "          0.03365306, -0.08271936],\n",
       "        [-0.14571056, -0.14093871,  0.13690162, ...,  0.10139184,\n",
       "         -0.31094766, -0.24536903],\n",
       "        [ 0.07281098,  0.07459906, -0.06961609, ..., -0.0524181 ,\n",
       "         -0.23165525,  0.00176561],\n",
       "        ...,\n",
       "        [-0.00869131,  0.0094894 , -0.16409372, ..., -0.09240545,\n",
       "         -0.0110344 , -0.19171141],\n",
       "        [ 0.09916285,  0.21496466,  0.19915083, ..., -0.1257529 ,\n",
       "          0.3159014 , -0.02061279],\n",
       "        [ 0.14555894,  0.17350572, -0.11013275, ...,  0.02240686,\n",
       "         -0.09719025,  0.01198233]], dtype=float32),\n",
       " array([0.36970484, 0.28028578, 0.29165736, 0.36983216, 0.438891  ,\n",
       "        0.37025654, 0.27447084, 0.30035716, 0.24856117, 0.4310613 ,\n",
       "        0.31833637, 0.40294212, 0.41294342, 0.32555437, 0.41683432,\n",
       "        0.3715813 , 0.47359115, 0.3007229 , 0.2830186 , 0.4216595 ,\n",
       "        0.4603424 , 0.5392978 , 0.3057896 , 0.23263542, 0.5729117 ,\n",
       "        0.4494142 , 0.33037314, 0.34735474, 0.28450188, 0.42724565,\n",
       "        0.49592364, 0.47074595, 0.30233425, 0.45464006, 0.48839566,\n",
       "        0.23695627, 0.26366174, 0.7057009 , 0.30515048, 0.32549596,\n",
       "        0.34663644, 0.43585804, 0.42686158, 0.41027486, 0.4896692 ,\n",
       "        0.3062337 , 0.4054149 , 0.41143072, 0.29380548, 0.46115655],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e6f2f6-6673-4421-9c90-664778b41828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 11:19:04.907364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58.022774"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[100]]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38dd97db-3e19-4d85-aff8-5d3ee831b00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.00000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func1(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99756ded-ec04-486d-ba58-32e192266c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
