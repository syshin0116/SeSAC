{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f31836c4-e409-4105-8120-3d9cbd9e16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96dc481f-7ccb-48fb-931c-407d2f70a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "\n",
    "db = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", password=\"peter2012!\", db=\"sba\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "sql = \"\"\"\n",
    "INSERT INTO link VALUES (NULL, 'test-test', 'link-test', 'keyword-test', 'content-test', 1, '2022-08-01', now())\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(sql)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d67976da-7a6d-4a99-8a3f-6e8e4bc72c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ABC', '에이비씨', 10, '경기', '031', '11122233', 170, datetime.date(2023, 8, 1))\n",
      "('APN', '에이핑크', 6, '경기', '031', '77777777', 164, datetime.date(2011, 2, 10))\n",
      "('BLK', '블랙핑크', 4, '경남', '055', '22222222', 163, datetime.date(2016, 8, 8))\n",
      "('GRL', '소녀시대', 8, '서울', '02', '44444444', 168, datetime.date(2007, 8, 2))\n",
      "('ITZ', '잇지', 5, '경남', None, None, 167, datetime.date(2019, 2, 12))\n",
      "('MMU', '마마무', 4, '전남', '061', '99999999', 165, datetime.date(2014, 6, 19))\n",
      "('OMY', '오마이걸', 7, '서울', None, None, 160, datetime.date(2015, 4, 21))\n",
      "('RED', '레드벨벳', 4, '경북', '054', '55555555', 161, datetime.date(2014, 8, 1))\n",
      "('SPC', '우주소녀', 13, '서울', '02', '88888888', 162, datetime.date(2016, 2, 25))\n",
      "('TWC', '트와이스', 9, '서울', '02', '11111111', 167, datetime.date(2015, 10, 19))\n",
      "('WMN', '여자친구', 6, '경기', '031', '33333333', 166, datetime.date(2015, 1, 15))\n"
     ]
    }
   ],
   "source": [
    "db = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", password=\"peter2012!\", db=\"market_db\")\n",
    "cursor = db.cursor()\n",
    "sql = \"\"\"\n",
    "SELECT * from member;\n",
    "\"\"\"\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchmany(size=100)\n",
    "for data in result:\n",
    "    print(data)\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b415d7b-8fa3-4334-89fe-92072901e85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 네이버 뉴스에서 파이썬 검색시 1000 페이지 크롤링\n",
    "import requests\n",
    "import pymysql\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "\n",
    "ua = UserAgent()\n",
    "headers = {\n",
    "    \"User-Agent\":ua.random\n",
    "}\n",
    "\n",
    "db = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", password=\"peter2012!\", db=\"sba\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "for i in range(10):\n",
    "    url=f\"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=41&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start={i*10+1}\"\n",
    "    res = requests.get(url, headers=headers)\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        print(i)\n",
    "        ul = bs.select_one('#main_pack > section > div > div.group_news > ul')#main_pack > section > div > div.group_news > ul\n",
    "        divs = ul.select('div.news_wrap.api_ani_send')\n",
    "        for div in divs:\n",
    "            title = div.select_one('a.news_tit').text.replace(\"'\", '\"')\n",
    "            link = div.select_one('a.news_tit').attrs.get(\"href\").replace(\"'\", '\"')\n",
    "            content = div.select_one('a.dsc_txt_wrap').text.replace(\"'\", '\"')\n",
    "            count = content.count('파이썬')\n",
    "            sql = f\"\"\"\n",
    "            INSERT INTO link VALUES (NULL, '{title}', '{link}', '파이썬', '{content}', {count}, '2022-08-01', now())\n",
    "            \"\"\"\n",
    "            cursor.execute(sql)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        print(\"error\", i)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6762eefe-af4a-41ba-b67c-71faf8d48a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "error 0 ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "1\n",
      "error 1 ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "## 각 링크 안에 있는 내용을 읽어와서 content에 저장\n",
    "# count도 실제 content에서 갯수를 세서 저장\n",
    "# content가 너무 길다는 에러 메시지가 나온다면 content[:10000] 슬라이싱 해서 저장\n",
    "\n",
    "# 네이버 뉴스에서 파이썬 검색시 1000 페이지 크롤링\n",
    "import requests\n",
    "import pymysql\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "\n",
    "ua = UserAgent()\n",
    "headers = {\n",
    "    \"User-Agent\":ua.random\n",
    "}\n",
    "\n",
    "db = pymysql.connect(host=\"localhost\", port=3306, user=\"root\", password=\"peter2012!\", db=\"sba\")\n",
    "cursor = db.cursor()\n",
    "\n",
    "for i in range(10):\n",
    "    url=f\"https://search.naver.com/search.naver?where=news&sm=tab_pge&query=%ED%8C%8C%EC%9D%B4%EC%8D%AC&sort=0&photo=0&field=0&pd=0&ds=&de=&cluster_rank=41&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:all,a:all&start={i*10+1}\"\n",
    "    res = requests.get(url, headers=headers)\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        print(i)\n",
    "        ul = bs.select_one('#main_pack > section > div > div.group_news > ul')#main_pack > section > div > div.group_news > ul\n",
    "        divs = ul.select('div.news_wrap.api_ani_send')\n",
    "        for div in divs:\n",
    "            title = div.select_one('a.news_tit').text.replace(\"'\", '\"')\n",
    "            link = div.select_one('a.news_tit').attrs.get(\"href\").replace(\"'\", '\"')\n",
    "            headers = {\"User-Agent\":ua.random}\n",
    "            content = requests.get(link, headers=headers).text[:10000].replace(\"'\", '\"')\n",
    "            count = content.count('파이썬')\n",
    "            sql = f\"\"\"\n",
    "            INSERT INTO link VALUES (NULL, '{title}', '{link}', '파이썬2', '{content}', {count}, '2022-08-01', now())\n",
    "            \"\"\"\n",
    "            cursor.execute(sql)\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(\"error\", i, e)\n",
    "db.commit()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf907f-e7d0-4630-a186-870069bcf028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
